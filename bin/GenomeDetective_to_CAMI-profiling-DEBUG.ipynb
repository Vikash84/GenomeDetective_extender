{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome Detective output conversion to CAMI profiling\n",
    "\n",
    "Author: Sam Nooij  \n",
    "Date: 2018-05-24\n",
    "\n",
    "\n",
    "Input: ## what exactly do I need...?\n",
    "- sample ID\n",
    "- taxon\n",
    "- number of reads\n",
    "- total reads\n",
    "\n",
    "    - These data (for both the assignments and the discoveries) can be derived from: the \"bokeh input\", output by `GenomeDetective_heatmaps.py`\n",
    "\n",
    "- NCBI taxonomy DB (through ETE toolkit, see [this tutorial](http://etetoolkit.org/docs/2.3/tutorial/tutorial_ncbitaxonomy.html))\n",
    "\n",
    "Output: table in [CAMI profiling format](https://github.com/bioboxes/rfc/blob/60263f34c57bc4137deeceec4c68a7f9f810f6a5/data-format/profiling.mkd)\n",
    "\n",
    "Required python packages:\n",
    " - pandas\n",
    " - ete3\n",
    " \n",
    "For automatic use in snakemake. The corresponding snakemake rule should provide the input:\n",
    " - the parsed report file (\"results/GenomeDetective_results.csv\")\n",
    " - a name for the output (e.g. \"results/GenomeDetective_CAMI-profiling.tsv\")\n",
    " \n",
    "  ** Remember that an output has to be generated for each sample, separately! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required python libraries\n",
    "import pandas as pd         #dataframe and csv export\n",
    "from ete3 import NCBITaxa   #work with NCBI taxonomy\n",
    "\n",
    "#DATA_TABLE = snakemake.input[0]\n",
    "#PROFILES = snakemake.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging cell:\n",
    "DATA_TABLE = \"../tmp/bokeh_input.csv\"\n",
    "PROFILE = \"../results/GenomeDetective_CAMI-profiling.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(DATA_TABLE)\n",
    "samples = sorted(set(results_df[\"sample\"]))\n",
    "\n",
    "PROFILES = [ \"%s/%s_%s\" % ('/'.join(PROFILE.split('/')[:-1]), sample, PROFILE.split('/')[-1]) for sample in samples ]\n",
    "\n",
    "ncbi = NCBITaxa()\n",
    "#In case you need to update, uncomment the next line:\n",
    "#ncbi.update_taxonomy_database()\n",
    "\n",
    "#Create separate files for each sample\n",
    "for sample in samples:\n",
    "    #Pick the right (pro)file name, that matches the sample\n",
    "    profile = [ p for p in PROFILES if sample in p ][0]\n",
    "    \n",
    "    subset = results_df[results_df[\"sample\"] == sample]\n",
    "    taxa = subset[\"Assignment\"]\n",
    "    total_percentages = subset[\"percentage_of_total_reads\"]\n",
    "    \n",
    "    rank_list_list = []\n",
    "    output_list = []\n",
    "    \n",
    "    for name in taxa:\n",
    "        #remove names that have some addition in brackets,\n",
    "        # like \" (segment 1)\"\n",
    "        if ' (' in name:\n",
    "            original_name = name\n",
    "            name = name[:name.index(' (')]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        taxon_and_id = ncbi.get_name_translator([name])\n",
    "        #ncbi.get_name_translator() returns a dictionary { 'taxon' : [id]}\n",
    "        taxid = taxon_and_id[name]\n",
    "        #taxid is a list with one number\n",
    "        taxid_nr = taxid[0]\n",
    "\n",
    "        rank_dict = ncbi.get_rank(taxid)\n",
    "        #ncbi.get_rank() requires a list of IDs, and returns a dictionary:\n",
    "        # {id: 'rank'}\n",
    "        rank = rank_dict[taxid_nr]\n",
    "\n",
    "        tax_path_dict = ncbi.get_lineage_translator(taxid)#[taxid_nr]\n",
    "        #ncbi.get_lineage_translator() requires a list of IDs, and returns\n",
    "        # a dictionary {leaf_id: [root_id, node_id, leaf_id]}\n",
    "        tax_path = tax_path_dict[taxid_nr][1:]\n",
    "\n",
    "        tax_path_sn = []\n",
    "        #with a for-loop you can translate the taxids in the list\n",
    "        # 'tax_path' to their corresponding scientific names (sn)\n",
    "        for t in tax_path:\n",
    "            tax_path_sn.append(ncbi.get_taxid_translator([t])[t])\n",
    "\n",
    "        rank_list = []\n",
    "        #Making this list requires using a for-loop;\n",
    "        # using the function on a list makes an UNORDERED dictionary\n",
    "        #Also, since the path differs between branches, I will look\n",
    "        # for the longest using a list of lists\n",
    "        for taxid in tax_path:\n",
    "            rank_dict = ncbi.get_rank([taxid])\n",
    "            rank = rank_dict[taxid]\n",
    "            rank_list.append(rank)\n",
    "\n",
    "        rank_list_list.append(rank_list)    \n",
    "\n",
    "        tax_path_string = '|'.join(map(str, tax_path))\n",
    "        tax_path_sn_string = '|'.join(tax_path_sn)\n",
    "        \n",
    "        try:\n",
    "            percentage = subset.loc[subset[\"Assignment\"] == name][\"percentage_of_total_reads\"].values[0]\n",
    "        except:\n",
    "            percentage = subset.loc[subset[\"Assignment\"] == original_name][\"percentage_of_total_reads\"].values[0]\n",
    "\n",
    "        output_line = \"%s\\t%s\\t%s\\t%s\\t%s\" % (taxid_nr, rank, tax_path_string, tax_path_sn_string, percentage)\n",
    "        \n",
    "        output_list.append(output_line)\n",
    "        \n",
    "    longest_taxonomy = '|'.join(max(rank_list_list, key = len))\n",
    "    \n",
    "    #Read the specification for details about this header:\n",
    "    #https://github.com/bioboxes/rfc/blob/60263f34c57bc4137deeceec4c68a7f9f810f6a5/data-format/profiling.mkd\n",
    "    header = \"\"\"# Taxonomic Profiling Output\n",
    "@SampleID:%s\n",
    "@Version:0.9.3\n",
    "@Ranks:%s\\t#the longest path in this sample: virus taxonomy is messy\n",
    "@TaxonomyID:ncbi-taxonomy_2018-05-25\n",
    "@@TAXID\\tRANK\\tTAXPATH\\tTAXPATHSN\\tPERCENTAGE\n",
    "\"\"\" % (sample, longest_taxonomy)\n",
    "    \n",
    "    with open(profile, 'w') as output_table:\n",
    "        output_table.write(header)\n",
    "        output_table.write('\\n'.join(output_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
