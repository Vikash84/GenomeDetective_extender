{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome Detective report writer script\n",
    "\n",
    "Author: Sam Nooij  \n",
    "Date: 2018-05-18\n",
    "\n",
    "Input:\n",
    "1. parsed XML file (e.g. \"tmp/GenomeDetective_results.csv\") as generated by bin/GenomeDetective_XML_parser.py\n",
    "2. result CSV files as generated by [GenomeDetective](http://www.genomedetective.com/app/typingtool/virus/)\n",
    "\n",
    "Output: table in csv format, providing:\n",
    "- run_id\n",
    "- sample_id\n",
    "- total_reads\n",
    "- low_quality_reads\n",
    "- non_viral_reads\n",
    "- viral_reads \n",
    "- pcr_result\n",
    "- ct_value \n",
    "- ngs_results\n",
    "- coverage%\n",
    "- contigs\n",
    "- number_of_reads\n",
    "- fraction_of_total_reads\n",
    "- percentage_of_total\n",
    "- fraction_of_viral_reads\n",
    "- percentage_of_viral\n",
    "- pcr_ngs_congruence\n",
    "- pcr_ngs_comments\n",
    "- human_virus_reads\n",
    "- plant_virus_reads\n",
    "- phage_reads\n",
    "- other_viral_reads\n",
    "- runtime\n",
    "\n",
    "Required python packages:\n",
    " - pandas\n",
    " \n",
    "For automatic use in snakemake. The corresponding snakemake rule should provide the input:\n",
    " - the parsed XML file (\"tmp/GenomeDetective_results.csv\")\n",
    " - a list of CSV files (their names, as strings; e.g. [ \"1_a_results.csv\", \"1_b_results.csv\" ]\n",
    " - a name for the output (e.g. \"tmp/GenomeDetective-PCR_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snakemake' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-458b75aafd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m         \u001b[0;31m#dataframe and csv export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mCSV_FILES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnakemake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mPARSED_XML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnakemake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parsed_xml'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mOUTPUT_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnakemake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'snakemake' is not defined"
     ]
    }
   ],
   "source": [
    "#Import required python libraries\n",
    "import pandas as pd         #dataframe and csv export\n",
    "\n",
    "CSV_FILES = snakemake.input['csv']\n",
    "PARSED_XML = snakemake.input['parsed_xml']\n",
    "OUTPUT_FILE = snakemake.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parser functions\n",
    "def pull_sample_name(filename):\n",
    "    \"\"\"\n",
    "    The sample and run IDs are in the filename, e.g.:\n",
    "    \"3_10_results.xml\"\n",
    "    where the 3 is the run ID, and the 10 is the sample ID\n",
    "    \"\"\"\n",
    "    error_msg = \"\"\"\n",
    "Expected underscores in the filename with the sample ID, e.g.\n",
    "3_1_results.xml\n",
    "Please provide sample names in this format.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert filename.count('_') >= 2, \\\n",
    "        \"%s\" % error_msg\n",
    "        \n",
    "    run_id = filename.split('/')[-1].split('_')[0]\n",
    "    \n",
    "    if filename.count('_') > 2:\n",
    "        sample_id = '_'.join(filename.split('/')[-1].split('_')[1:-1])\n",
    "    else:\n",
    "        sample_id = filename.split('/')[-1].split('_')[1]\n",
    "    \n",
    "    return run_id, sample_id\n",
    "\n",
    "def create_concatenated_dataframe(csv_list):\n",
    "    \"\"\"\n",
    "    Input: a list of Genome Detective output CSV files,\n",
    "          e.g. [\"3_1_results.csv\", \"4_D_results.csv\"]\n",
    "    Output: One concatenated dataframe of all the input files\n",
    "    \"\"\"\n",
    "    csv_list = sorted(csv_list)\n",
    "    \n",
    "        \n",
    "    #Step 2: open the files as dataframe, remove \"Contigs\" column and add sample IDs\n",
    "    df_list = []\n",
    "    for results_file in csv_list:\n",
    "        results_df = pd.read_csv(results_file)\n",
    "        results_df = results_df.drop(\"Contigs\", axis = 1) #remove unnecessary (and long!) column\n",
    "        run_id, sample_id = pull_sample_name(results_file)\n",
    "        results_df[\"run_id\"] = run_id\n",
    "        results_df[\"sample_id\"] = sample_id\n",
    "        df_list.append(results_df)\n",
    "\n",
    "    #Step 3: concatenate the dataframes\n",
    "    super_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return(super_df)\n",
    "\n",
    "def combine_tables(parsed_xml, csv_list):\n",
    "    \"\"\"\n",
    "    Input: 1. parsed XML table, with the fields:\n",
    "    run_id sample_id total_reads low_quality_reads non_viral_reads viral_reads runtime\n",
    "           2. CSV results files, with the fields:\n",
    "    Assignment # Contigs Mapped # Reads Coverage (%) Mapped depth <br/>of Coverage NT Identity (%) AA Identity (%) Contigs\n",
    "    Output: one table with the fields:\n",
    "    run_id sample_id total_reads low_quality_reads non_viral_reads viral_reads  pcr_result ct_value ngs_results coverage% contigs number_of_reads fraction_of_total_reads fraction_of_viral_reads pcr_ngs_congruence pcr_ngs_comments human_virus_reads plant_virus_reads phage_reads other_viral_reads runtime\n",
    "    \"\"\"\n",
    "    xml_df = pd.read_csv(parsed_xml)\n",
    "    csv_df = create_concatenated_dataframe(csv_list)\n",
    "    csv_df[\"run_id\"] = csv_df[\"run_id\"].apply(int)\n",
    "    #This column was read as strings and could not merge with\n",
    "    # xml_df, because that contained integers...\n",
    "        \n",
    "    desired_columns = \\\n",
    "    {\"run_id\": \"a\",\"sample_id\": \"a\",\"total_reads\": \"a\",\n",
    "     \"low_quality_reads\": \"a\",\"non_viral_reads\": \"a\",\n",
    "     \"viral_reads\": \"a\",\"pcr_result\": \"m\", \"ct_value\": \"m\",\n",
    "     \"GD_assignment\": \"a\",\"coverage%\": \"a\",\n",
    "     \"contigs\": \"a\",\"number_of_reads\": \"a\",\n",
    "     \"fraction_of_total_reads\": \"c\",\"fraction_of_viral_reads\": \"c\",\n",
    "     \"pcr_ngs_congruence\": \"m\", \"pcr_ngs_comments\": \"m\",\n",
    "     \"human_virus_reads\": \"m\", \"plant_virus_reads\": \"m\",\n",
    "     \"phage_reads\": \"m\", \"other_viral_reads\": \"m\",\"runtime\": \"a\"}\n",
    "    #a = available data (can copy), m = manual filling, c = calculate\n",
    "\n",
    "    original_columns = \\\n",
    "    {\n",
    "        \"GD_assignment\": \"Assignment\", \"contigs\": \"# Contigs\",\n",
    "        \"number_of_reads\": \"Mapped # Reads\", \"coverage%\": \"Coverage (%)\",\n",
    "    }\n",
    "    report_df = xml_df\n",
    "    empty = \"fill me in\"\n",
    "    \n",
    "    #First step: merge the 'a' part\n",
    "    report_df = report_df.merge(csv_df, how = \"right\", on = [\"run_id\", \"sample_id\"])\n",
    "\n",
    "    #Second step: fill in the gaps\n",
    "    for key, value in desired_columns.items():\n",
    "        if value == \"m\":\n",
    "        #These have to be filled manually\n",
    "            report_df[key] = empty\n",
    "\n",
    "        elif value == \"a\":\n",
    "        #These data are avaible and automatically filled in\n",
    "            if key in report_df:\n",
    "                pass\n",
    "            else:\n",
    "                #check if the column name is different\n",
    "                if key in original_columns:\n",
    "                    key = original_columns[key]\n",
    "                #report it missing if it is still not there\n",
    "                if key not in report_df:\n",
    "                    print(\"%s is a missing column\" % key)\n",
    "                #If it is in the dataframe already, pass\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        elif value == \"c\":\n",
    "        #These data have to be calculated with what is available\n",
    "            if \"total\" in key:\n",
    "                report_df = report_df.assign(\n",
    "                    fraction_of_total_reads=lambda report_df:\n",
    "                    report_df[\"Mapped # Reads\"] / report_df.total_reads)\n",
    "                #fraction = number / total_reads\n",
    "                report_df = report_df.assign(\n",
    "                    percentage_of_total=lambda report_df:\n",
    "                    report_df.fraction_of_total_reads * 100)\n",
    "                #percentage = fraction * 100\n",
    "            elif \"viral\" in key:\n",
    "                report_df = report_df.assign(\n",
    "                    fraction_of_viral_reads=lambda report_df:\n",
    "                    report_df[\"Mapped # Reads\"] / report_df.viral_reads)\n",
    "                #fraction = number / viral_reads\n",
    "                report_df = report_df.assign(\n",
    "                    percentage_of_viral=lambda report_df:\n",
    "                    report_df.fraction_of_viral_reads * 100)\n",
    "                #percentage = fraction * 100\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    report_df = report_df.drop(\"Mapped depth <br/>of Coverage\", axis = 1)\n",
    "    \n",
    "    for key, value in original_columns.items():\n",
    "        report_df = report_df.rename(columns={value: key})\n",
    "\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PARSED_XML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2a989fb13115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Parse/collect the results in a Pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mreport_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPARSED_XML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSV_FILES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Reorder the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PARSED_XML' is not defined"
     ]
    }
   ],
   "source": [
    "#Script execution\n",
    "if __name__ == \"__main__\":\n",
    "    #Parse/collect the results in a Pandas dataframe\n",
    "    report_df = combine_tables(parsed_xml = PARSED_XML, csv_list = CSV_FILES)\n",
    "    \n",
    "    #Reorder the columns\n",
    "    column_order = [\"run_id\", \"sample_id\",\n",
    "                    \"pcr_result\", \"ct_value\", \n",
    "                    \"GD_assignment\", \"coverage%\", \"contigs\", \n",
    "                    \"pcr_ngs_congruence\", \"pcr_ngs_comments\",\n",
    "                    \"number_of_reads\", \"fraction_of_total_reads\", \n",
    "                    \"percentage_of_total\", \"fraction_of_viral_reads\", \n",
    "                    \"percentage_of_viral\",\n",
    "                    \"total_reads\", \"low_quality_reads\", \n",
    "                    \"non_viral_reads\", \"viral_reads\",\n",
    "                    \"human_virus_reads\", \"plant_virus_reads\",\n",
    "                    \"phage_reads\", \"other_viral_reads\", \"runtime\"]\n",
    "    \n",
    "    report_df = report_df[column_order]\n",
    "    \n",
    "    #And save it as a csv file\n",
    "    ??report_df.to_csv(OUTPUT_FILE, index = False)\n",
    "    \n",
    "    print(\"\"\"\\nDone!\n",
    "The results have been written to: %s\"\"\" % OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
